\section{Einleitung}
\label{section:Einleitung}


(TODO: write about callbacks)
(TODO: write about callstack)

\subsection{Performance}

Eine Applikation ist performant wenn diese einem EndbenutzerIn ein Aufgabe ausführen lässt ohne ein unangemessene Wartezeit für diesen hervorruft. Aus dieser Definition schließt sich dass die Performance im Auge des Betrachters liegt und es somit keine klar definierten Regeln für die Performance einer Applikation gibt. Es gibt jedoch einzelne Indikatoren an denen man die Performance von Applikationen vergleichen kann. Dabei kann man in \emph{Service orientierter Performance} und \emph{Effektiv orientierter Performance} unterteilen \cite[p. 2]{Mol2009}.

\subsubsection{Service orientierte Performance}

\emph{Service orientierte Performance} beschreibt wie gut eine Applikation einen Service für den EndbenutzerIn zur verfügung stellt \cite[p. 2]{Mol2009}:

\begin{itemize}
  \item {Verfügbarkeit:} beschreibt die Menge an Zeit in welcher eine Applikation für den EndbenutzerIn verfügbar ist.
  \item \emph{Antwortzeit:} beschreibt die Zeit die eine Applikation für die Antwort auf eine Anfrage benötigt.
\end{itemize}


\subsubsection{Effektiv orientierte Performance}

\emph{Effektiv orientierte Performance} beschreibt wie gut eine Applikation die Ausführumgebung verwendet \cite[p. 2]{Mol2009}:

\begin{itemize}
  \item \emph{Durchsatz:} Wie viele Anfragen eine Applikation in einer Zeiteinheit verarbeiten kann.
  \item \emph{Ressourcenverbauch:} Wie viel Prozent der Verfügbaren Ressourcen eine Applikation verwendet.
\end{itemize}


\subsection{Concurrency}
\label{section:concurrency}

Concurrency laut Robert Pike ist das behandeln von mehreren Operationen zur selben Zeit. Dabei geht es um die Art und Weise wie mehrere Operationen in einem nicht linearen Programmierfluss behandelt werden. Eine Applikation welche concurrent ist demnach muss nicht zwangsweise zur gleichen Zeit ausgeführt werden. Bei einer Applikation welche concurrent Aufgebaut ist, ist das Ziel ein gutes Design der Applikation zu erreichen. \cite[]{Pik2013}

Dabei können Concurrent Applikationen in folgenden Reihenfolgen abgearbeitet werden \cite[p. 14]{Erb2012}:

\begin{itemize}
  \item Sie werden sequenziell abgearbeitet (die Reihenfolge spielt dabei keine Rolle)
  \item Sie werden abwechseln abgearbeitet
  \item Sie werden parallel abgearbeitet
\end{itemize}

\subsection{Parallelismus}
Parallelismus beschreibt das gleichzeitige Ausführen von Operationen. Genauer handelt es sich bei Parallelismus um die Art und Weise wie ein Progam ausgeführt wird. Parallelismus ist auch eine Kondition die auftritt wenn mindestens zwei Threads gleichzeitig ausgeführt werden \cite[]{oracle:multithreading}.

Im allgemeinen können Operationen auf einem Computer in folgenden Umgebungen ausgeführt werden \cite[p. 14]{Erb2012}:

\begin{itemize}
  \item Single Core Prozessoren
  \item Multi Core Prozessoren
  \item Multi Prozessoren
  \item Unterschiedliche Maschinen in einem Distributed System
\end{itemize}

Das Hauptziel von paralleler Programierung ist nach Robert Pike das gleichzeitige oder simultane ausführen von Operationen auf zwei oder mehreren CPUs.\cite[]{Pik2013} Parallelität kann demnach nur auf den Umgebungen 2-4 auftreten.

Das gleichzeitige Ausführen von Operationen kann zu einer Steigerung der Performance einer Applikation führen \cite[p. 18]{Can08}.

\subsection{Concurrency vs. Parallelismus}

Ein Betriebssystem besitzt unterschiedliche I/O Devices (z.B. Maus, Keyboard, Touchpad, etc.). Dabei können Eingaben zu jeder Zeit von einem Benutzer durchgeführt werden. Atomare Eingaben wie das Tippen eines Buchstabens sind ebenso Möglich wie das parallele Eingaben drücken von mehreren Tasten (z.B. STRG+S zum speichern eines Dokuments). Um diese Informationen zu verarbeiten benötigt das Betriebssystem ein Concurrency Model. Dieses Concurrency Model kann entweder Linear oder Parallel ausgeführt werden. \cite[]{Pik2013}

In der Literatur finden sich unterschiedliche Definitionen über Parallelismus und Concurrency. Oft wird zwischen diesen beiden Definitionen jedoch nicht unterschieden.

In dieser Thesis wird von Parallelität gesprochen wenn zwei Aufgaben auf zwei CPU parallel abgearbeitet werden. Virtueller Parallelismus bei dem Threads durch Time-Slicing abwechselnd ausgeführt werden, wird in dieser Thesis nicht als Parallelismus bezeichnet. Von Concurrency wird in dieser Thesis gesprochen wenn mindestens zwei Operationen auf der CPU sequenziell oder abwechselnd abgearbeitet werden.


\subsection{Performance}
(TODO: write/refactor)

Teile einer Applikation welche keinen gemeinsamen Status besitzen und sequentiell abgearbeitet werden können mit wenig Aufwand parallel ausgeführt werden. \cite[p. 18]{Can08}

Ein konkretes Beispiel dazu bietet ein Webserver. Mehrere Anfragen werden von unterschiedlichen Clients an einen HTTP-Webserver gesendet, welcher die Anfragen gleichzeitig verarbeitet. Der Webserver leitet die Anfragen an ein das zugehörige Program weiter welches den jeweiligem HTTP-Response sequentiell generiert. \cite[p. 18]{Can08}

Für einen modernen Webserver müssen folgende Bedingungen erfüllt sein \cite[p. 2]{Sch97}:
\label{Webserver_Requirements}
\emph{Concurrency}
	Ein Server muss mehrere Anfragen von Clients gleichzeitig verarbeiten können.

\emph{Efficiency}
	Der Server muss Latenzen gering halten und die CPU nicht unnötig belasten.

\emph{Programming simplicity}
	Der Server muss einfache Schnittstellen für Concurrent Programming bieten (TODO: concurrent programming?)

\emph{Adaptability}
	Neue Protokolle wie HTTP 2.0 sollten mit minimalen Implementierungsaufwand realisierbar sein.


\subsection{Synchrone Programmierung}
(TODO: write Section)

\subsection{Asynchrone Programmierung}

(TODO: write Section)

\subsection{Asynchrone Programmierung vs Synchrone Programmierung}
(TODO: write Section)

\subsection{Event getriebene Programmierung}
(TODO: write Section)
(TODO: write about dispatching and demultiplexing)
(TODO: write about callback functions)

\subsection{Lambdas}
Lambdas werden auch als Closures, anonyme Functions oder Blocks genannt. Lambdas sind Blöcke aus Quellcode welcher als Argument an eine Funktion übergeben werden kann. Unter anderem werden Lambdas in den folgenden Programmiersprachen unterstützt:

\begin{itemize}
  \item Lisp
  \item Ruby
  \item Javascript
  \item Java
  \item Smalltalk
\end{itemize}

Closures können auf lokale Variablen zugreifen. Das bedeutet dass eine Closure auf alle Variablen im aktuellen Kontext zugriff haben. In der Sprache Ruby werden Closures unter anderem mit geschwungenen Klammeren erstellt. \cite[]{fow04}

\begin{lstlisting}[
	caption={},
	label=listing:closures
]
	File.open(filename) {|f| doSomethingWithFile(f)}
\end{lstlisting}
\cite[]{fow04}

In Listing \ref{listing:closures} wird eine Datei vom lokalem Filesystem geöffnet. Die Funktion open in der File Klasse akzeptiert einen Block als Argument. Die Funktion open öffnet die Datei, führt den angegebenen Block aus und schließt nach Ausführung des Blocks die Datei. Blöcke können unter anderem in Transaktionen verwendet werden. \cite[]{fow04}


\subsection{select(2)}
\emph{select(2)} ist ein Low Level System Aufruf der ein oder mehrere Dateien beobachten kann ob diese bereit für eine I/O Operation sind. Dabei wird überprüft ob eine Datei bereit zum Lesen oder Schreiben ist oder einen Fehler besitzt.


Beim Lesen einer Datei werden der erste Charackter der Datei überprüft ob dieser bereit ist zum lesen. Dadurch kann bestimmt werden ob die Datei eingelesen werden kann, ohne dass die I/O Operation blockiert.


\subsection{I/O Operations}
\label{subsection: io_operationen}
Eine Aufgabe eines Betriebssystems ist die Verwaltung von Ein- und Ausgabe (I/O = Input/Output). Besonders in grafischen Anwendungen spielt das Reagieren auf Benutzereingaben eine wichtige Rolle. Um zum Beispiel eine Datei zu öffnen wird die Eingabe des Benutzers verwendet um die Datei zu finden. Die Datei wird anschließend gelesen um den Inhalt am Monitor auszugeben.

In Applikationen können viele I/O Operationen zwischengespeichert werden bevor sie in die Applikation eintreffen. Dabei blockiert das Betriebssystem die restlichen Operationen so lange bis die Datei fertig eingelesen wurde. Im Anschluss können die Daten der Datei weiterverareitet werden \cite[p. 307]{tan09}. 

(TODO: refactor)

\subsubsection{Why I/O Speed Matters}
\label{subsection: i/o speed}
Die Nachfolgende Tabelle gibt einen groben Überblick wie lange einzelne I/O Operationen benötigen. Diese Tabelle beruht auf keinen wissenschaftlichen Quellen und sollte lediglich als grobe Referenz für die Dauer von I/O Operationen dienen. Diese Tabelle beruht auf den Zahlen von Peter Norvig \cite[]{Nor98} einem Director of Research bei Google und den Vergleichen des Github Benutzers hellerbarde \cite[]{Gis15}:

(TODO: check table if it fits on the page)
(TODO: ask Hannes if i can add this to my thesis)

\begin{table}[h]
\begin{tabular}{@{}lllll@{}}
\toprule
\textbf{I/O Operation}                                     & \textbf{Zeit in Nanosekunden} & \textbf{Zeit in ns mal 1 Mrd.} & \textbf{Vergleichswert}                                    &  \\ \midrule
Holen aus dem L1 Cache                                     & 0.5 ns                        & 0.5 s                          & Ein Herzschlag                                             &  \\
Führe eine typische Operation auf der CPU aus              & 1 ns                          & 1 s                            & (TODO: finde Vergleich)                                    &  \\
Holen aus dem L2 Cache                                     & 7 ns                          & 7 s                            & Gähnen                                                     &  \\
Mutex lock/unlock                                          & 25 ns                         & 25 s                           & einen Kaffee Zubereiten                                    &  \\
Holen vom Arbeitsspeicher                                  & 100 ns                        & 100 s                          & Zähneputzen                                                &  \\
Sende 2K Bytes über ein 1Gbps Netzwerk                     & 20,000 ns                     & 5.5 h                          & mehr als ein halber Arbeitstag                             &  \\
SSD random read                                            & 150,000 ns                    & 1,7 d                          & ein Wochenende                                             &  \\
Lese 1 MB sequentiell vom Arbeitsspeicher                  & 250,000 ns                    & 2.9 d                          & ein verlängertes Wochenende                                &  \\
Round Trip Time im selben Datencenter                      & 500,000 ns                    & 5.8 d                          & Eine kurze Reise                                           &  \\
Lese 1 MB sequentiell von einer SSD                        & 1,000,000 ns                  & 11.6 d                         & Eine lange Reise                                           &  \\
Suche auf einer normalen Festplatte                        & 10,000,000 ns                 & 16.5 kw                        & Ein Semester an der Universität                            &  \\
Lese 1 MB sequentiell von einer Festplatte                 & 20,000,000 ns                 & 7.8 m                          & Jänner bis ende August                                     &  \\
Auf der Festplatte eine 1 MB große Datei suchen und lesen  & 21,000,000 ns                 & 1 y                            & Ein Jahr                                                   &  \\
Sende ein Packet von Europa nach Amerika und wieder zurück & 150,000,000 ns                & 4.8 y                          & Bachelor + Master an der FH Salzburg in Mindeststudienzeit &  \\ \bottomrule
\end{tabular}
\end{table}