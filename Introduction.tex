\section{Einleitung}
\label{section:Einleitung}


\subsection{Performance}

Eine Applikation ist performant wenn diese einem EndbenutzerIn ein Aufgabe ausführen lässt ohne ein unangemessene Wartezeit für diesen hervorruft. Aus dieser Definition schließt sich dass die Performance im Auge des Betrachters liegt und es somit keine klar definierten Regeln für die Performance einer Applikation gibt. Es gibt jedoch einzelne Indikatoren an denen man die Performance von Applikationen vergleichen kann. Dabei kann man in \emph{Service orientierter Performance} und \emph{Effektiv orientierter Performance} unterteilen \cite[p. 2]{Mol2009}.

\subsubsection{Service orientierte Performance}

\emph{Service orientierte Performance} beschreibt wie gut eine Applikation einen Service für den EndbenutzerIn zur verfügung stellt \cite[p. 2]{Mol2009}:

\begin{itemize}
  \item {Verfügbarkeit:} beschreibt die Menge an Zeit in welcher eine Applikation für den EndbenutzerIn verfügbar ist.
  \item \emph{Antwortzeit:} beschreibt die Zeit die eine Applikation für die Antwort auf eine Anfrage benötigt. 
\end{itemize}    
    

\subsubsection{Effektiv orientierte Performance}

\emph{Effektiv orientierte Performance} beschreibt wie gut eine Applikation die Ausführumgebung verwendet \cite[p. 2]{Mol2009}:

\begin{itemize}
  \item \emph{Durchsatz:} Wie viele Anfragen eine Applikation in einer Zeiteinheit verarbeiten kann.
  \item \emph{Ressourcenverbauch:} Wie viel Prozent der Verfügbaren Ressourcen eine Applikation verwendet. 
\end{itemize}




(TODO: Threads add Time Slicing)
Durch Time-Slicing kann eine pseudo Parallelität auf einem einzelnen Prozessor erreicht werden. Durch diese Definition schließt sich, dass eine richtige Parallelität nur dann existiert wenn mehrere Aufgaben auf der selben Anzahl an Prozessorkernen ausgeführt werden. 







\subsection{Concurrency}
\label{section:concurrency}

Concurrency laut Robert Pike ist das behandeln von mehreren Operationen zur selben Zeit. Dabei geht es um die Art und Weise wie mehrere Operationen in einem nicht linearen Programmierfluss behandelt werden. Eine Applikation welche concurrent ist demnach muss nicht zwangsweise zur gleichen Zeit ausgeführt werden. Bei einer Applikation welche concurrent Aufgebaut ist, ist das Ziel ein gutes Design der Applikation zu erreichen. \cite[]{Pik2013}

Dabei können Concurrent Applikationen in folgenden Reihenfolgen abgearbeitet werden \cite[p. 14]{Erb2012}:

\begin{itemize}
  \item Sie werden sequenziell abgearbeitet (die Reihenfolge spielt dabei keine Rolle)
  \item Sie werden abwechseln abgearbeitet
  \item Sie werden parallel abgearbeitet
\end{itemize}

\subsection{Parallelismus}
Parallelismus beschreibt das gleichzeitige Ausführen von Operationen. Genauer handelt es sich bei Parallelismus um die Art und Weise wie ein Progam ausgeführt wird. Parallelismus ist auch eine Kondition die auftritt wenn mindestens zwei Threads gleichzeitig ausgeführt werden \cite[]{oracle:multithreading}.

Im allgemeinen können Operationen auf einem Computer in folgenden Umgebungen ausgeführt werden \cite[p. 14]{Erb2012}:

\begin{itemize}
  \item Single Core Prozessoren
  \item Multi Core Prozessoren
  \item Multi Prozessoren
  \item Unterschiedliche Maschinen in einem Distributed System
\end{itemize}

Das Hauptziel von paralleler Programierung ist nach Robert Pike das gleichzeitige oder simultane ausführen von Operationen auf zwei oder mehreren CPUs.\cite[]{Pik2013} Parallelität kann demnach nur auf den Umgebungen 2-4 auftreten. 
 

\subsection{Concurrency vs. Parallelismus}

Ein Betriebssystem besitzt unterschiedliche I/O Devices (z.B. Maus, Keyboard, Touchpad, etc.). Dabei können Eingaben zu jeder Zeit von einem Benutzer durchgeführt werden. Atomare Eingaben wie das Tippen eines Buchstabens sind ebenso Möglich wie das parallele Eingaben drücken von mehreren Tasten (z.B. STRG+S zum speichern eines Dokuments). Um diese Informationen zu verarbeiten benötigt das Betriebssystem ein Concurrency Model. Dieses Concurrency Model kann entweder Linear oder Parallel ausgeführt werden. \cite[]{Pik2013}

In der Literatur finden sich unterschiedliche Definitionen über Parallelismus und Concurrency. Oft wird zwischen diesen beiden Definitionen jedoch nicht unterschieden.

In dieser Thesis wird von Parallelität gesprochen wenn zwei Aufgaben auf zwei CPU parallel abgearbeitet werden. Virtueller Parallelismus bei dem Threads durch Time-Slicing abwechselnd ausgeführt werden, wird in dieser Thesis nicht als Parallelismus bezeichnet. Von Concurrency wird in dieser Thesis gesprochen wenn mindestens zwei Operationen auf der CPU sequenziell oder abwechselnd abgearbeitet werden.



\subsection{Performance}
(TODO: write/refactor)

Das gleichzeitige Ausführen von Operationen kann zu einer Steigerung der Performance einer Applikation führen. Die Steigerung von Performance kann in drei Kategorien unterteilt werden \cite[p. 18]{Can08}:

\emph{Reduzierte Latenzen}
	Eine Aufgabe wird in schneller ausgeführt indem sie in kleinere Aufgaben unterteilt wird, welche gleichzeitig abgearbeitet werden können. \cite[p. 18]{Can08}

\emph{Latenzen verstecken}
	Lang andauernde Aufgaben werden gebündelt und abgearbeitet. Gleichzeitig können andere Aufgaben abgearbeitet werden bis die lang andauernden Aufgaben erledigt sind. Dies kann besonders bei Netzwerk oder Festplatten Operationen sinnvoll sein da diese ansonsten den Programfluss blockeren können.

\emph{Die Menge an verarbeiteten Daten pro Zeiteinheit zu veringern}
	Wenn mehrere Tasks gleichzeitig Ausgeführt werden kann die Menge an verarbeiten Daten pro Zeiteinheit erhöht werden.	

In verteilten Systemen wie Web Applikationen ist die parallele Ausführung ein essentieller Bestandteil \cite[p. 14]{Erb2012}. 

Teile einer Applikation welche keinen gemeinsamen Status besitzen und sequentiell abgearbeitet werden können mit wenig Aufwand parallel ausgeführt werden. \cite[p. 18]{Can08}

Ein konkretes Beispiel dazu bietet ein Webserver. Mehrere Anfragen werden von unterschiedlichen Clients an einen HTTP-Webserver gesendet, welcher die Anfragen gleichzeitig verarbeitet. Der Webserver leitet die Anfragen an ein das zugehörige Program weiter welches den jeweiligem HTTP-Response sequentiell generiert. \cite[p. 18]{Can08}

Für einen modernen Webserver müssen folgende Bedingungen erfüllt sein \cite[p. 2]{Sch97}: 
\label{Webserver_Requirements}
\emph{Concurrency}
	Ein Server muss mehrere Anfragen von Clients gleichzeitig verarbeiten können. 

\emph{Efficiency}
	Der Server muss Latenzen gering halten und die CPU nicht unnötig belasten. 

\emph{Programming simplicity}
	Der Server muss einfache Schnittstellen für Concurrent Programming bieten (TODO: concurrent programming?)

\emph{Adaptability}
	Neue Protokolle wie HTTP 2.0 sollten mit minimalen Implementierungsaufwand realisierbar sein.



\subsection{Synchrone Programmierung}
(TODO: write Section)

\subsection{Asynchrone Programmierung}



(TODO: write Section)

\subsection{Asynchrone Programmierung vs Synchrone Programmierung}
(TODO: write Section)

\subsection{Event getriebene Programmierung}
(TODO: write Section)
(TODO: write about dispatching and demultiplexing)
(TODO: write about callback functions)

\subsection{Lambdas}
Lambdas werden auch als Closures, anonyme Functions oder Blocks genannt. Lambdas sind Blöcke aus Quellcode welcher als Argument an eine Funktion übergeben werden kann. Unter anderem werden Lambdas in den folgenden Programmiersprachen unterstützt:

\begin{itemize}
  \item Lisp
  \item Ruby
  \item Javascript
  \item Java
  \item Smalltalk
\end{itemize}

Closures können auf lokale Variablen zugreifen. Das bedeutet dass eine Closure auf alle Variablen im aktuellen Kontext zugriff haben. In der Sprache Ruby werden Closures unter anderem mit geschwungenen Klammeren erstellt. \cite[]{fow04} 

\begin{lstlisting}[
	caption={},
	label=listing:closures
]
	File.open(filename) {|f| doSomethingWithFile(f)}
\end{lstlisting}
\cite[]{fow04}

In Listing \ref{listing:closures} wird eine Datei vom lokalem Filesystem geöffnet. Die Funktion open in der File Klasse akzeptiert einen Block als Argument. Die Funktion open öffnet die Datei, führt den angegebenen Block aus und schließt nach Ausführung des Blocks die Datei. Blöcke können unter anderem in Transaktionen verwendet werden. \cite[]{fow04}


\subsection{I/O Operations}



(TODO: write Section)

\subsubsection{Why I/O Speed Matters}


\begin{table}[h]
\begin{tabular}{@{}lllll@{}}
\toprule
\textbf{I/O Operation}                                     & \textbf{Zeit in Nanosekunden} & \textbf{Zeit in ns mal 1 Mrd.} & \textbf{Vergleichswert}                                    &  \\ \midrule
Holen aus dem L1 Cache                                     & 0.5 ns                        & 0.5 s                          & Ein Herzschlag                                             &  \\
Führe eine typische Operation auf der CPU aus              & 1 ns                          & 1 s                            & (TODO: finde Vergleich)                                    &  \\
Holen aus dem L2 Cache                                     & 7 ns                          & 7 s                            & Gähnen                                                     &  \\
Mutex lock/unlock                                          & 25 ns                         & 25 s                           & einen Kaffee Zubereiten                                    &  \\
Holen vom Arbeitsspeicher                                  & 100 ns                        & 100 s                          & Zähneputzen                                                &  \\
Sende 2K Bytes über ein 1Gbps Netzwerk                     & 20,000 ns                     & 5.5 h                          & mehr als ein halber Arbeitstag                             &  \\
SSD random read                                            & 150,000 ns                    & 1,7 d                          & ein Wochenende                                             &  \\
Lese 1 MB sequentiell vom Arbeitsspeicher                  & 250,000 ns                    & 2.9 d                          & ein verlängertes Wochenende                                &  \\
Round Trip Time im selben Datencenter                      & 500,000 ns                    & 5.8 d                          & Eine kurze Reise                                           &  \\
Lese 1 MB sequentiell von einer SSD                        & 1,000,000 ns                  & 11.6 d                         & Eine lange Reise                                           &  \\
Suche auf einer normalen Festplatte                        & 10,000,000 ns                 & 16.5 kw                        & Ein Semester an der Universität                            &  \\
Lese 1 MB sequentiell von einer Festplatte                 & 20,000,000 ns                 & 7.8 m                          & Jänner bis ende August                                     &  \\
Auf der Festplatte eine 1 MB große Datei suchen und lesen  & 21,000,000 ns                 & 1 y                            & Ein Jahr                                                   &  \\
Sende ein Packet von Europa nach Amerika und wieder zurück & 150,000,000 ns                & 4.8 y                          & Bachelor + Master an der FH Salzburg in Mindeststudienzeit &  \\ \bottomrule
\end{tabular}
\end{table}



(TODO: add statistiks about Disk I/O, Network I/O, Memory I/O)