\section{Einleitung}
\label{section:Einleitung}



\subsection{Performance}
(TODO: was ist Performance)

(TODO: linear vs. non linear programmierfluss)

(TODO: Threads add Time Slicing)
Durch Time-Slicing kann eine pseudo Parallelität auf einem einzelnen Prozessor erreicht werden. Durch diese Definition schließt sich, dass eine richtige Parallelität nur dann existiert wenn mehrere Aufgaben auf der selben Anzahl an Prozessorkernen ausgeführt werden. 


\subsection{Concurrency}
\label{section:concurrency}

Concurrency laut Robert Pike ist das behandeln von mehreren Operationen zur selben Zeit. Dabei geht es um die Art und Weise wie mehrere Operationen in einem nicht linearen Programmierfluss behandelt werden. Eine Applikation welche concurrent ist demnach muss nicht zwangsweise zur gleichen Zeit ausgeführt werden. Bei einer Applikation welche concurrent Aufgebaut ist, ist das Ziel ein gutes Design der Applikation zu erreichen. \cite[]{Pik2013}

Dabei können Concurrent Applikationen in folgenden Reihenfolgen abgearbeitet werden \cite[p. 14]{Erb2012}:

\begin{itemize}
  \item Sie werden sequenziell abgearbeitet (die Reihenfolge spielt dabei keine Rolle)
  \item Sie werden abwechseln abgearbeitet
  \item Sie werden parallel abgearbeitet
\end{itemize}


\subsection{Parallelismus}
Parallelismus beschreibt das gleichzeitige Ausführen von Operationen. Genauer handelt es sich bei Parallelismus um die Art und Weise wie ein Progam ausgeführt wird. Parallelismus ist auch eine Kondition die auftritt wenn mindestens zwei Threads gleichzeitig ausgeführt werden \cite[]{oracle:multithreading}. Daraus schließt sich, dass auf einem Single Core Prozessor keine Operationen Parallel durchgeführt werden können \cite[]{Pik2013}.

Im allgemeinen können Operationen auf einem Computer in folgenden Umgebungen ausgeführt werden \cite[p. 14]{Erb2012}:

\begin{itemize}
  \item Single Core Prozessoren
  \item Multi Core Prozessoren
  \item Multi Prozessoren
  \item Unterschiedliche Maschinen in einem Distributed System
\end{itemize}

Das Hauptziel von paralleler Programierung ist nach Robert Pike das gleichzeitige oder simultane ausführen von Operationen auf zwei oder mehreren CPUs.\cite[]{Pik2013} Parallelität kann demnach nur auf den Umgebungen 2-4 auftreten. 
 

\subsection{Concurrency vs. Parallelismus}

Ein Betriebssystem besitzt unterschiedliche I/O Devices (z.B. Maus, Keyboard, Touchpad, etc.). Dabei können Eingaben zu jeder Zeit von einem Benutzer durchgeführt werden. Atomare Eingaben wie das Tippen eines Buchstabens sind ebenso Möglich wie das parallele Eingaben drücken von mehreren Tasten (z.B. STRG+S zum speichern eines Dokuments). Um diese Informationen zu verarbeiten benötigt das Betriebssystem ein Concurrency Model. Dieses Concurrency Model kann entweder Linear oder Parallel ausgeführt werden. \cite[]{Pik2013}

In der Literatur finden sich unterschiedliche Definitionen über Parallelismus und Concurrency. Oft wird zwischen diesen beiden Definitionen jedoch nicht unterschieden.

In dieser Thesis wird von Parallelität gesprochen wenn zwei Aufgaben auf zwei CPU parallel abgearbeitet werden. Virtueller Parallelismus bei dem Threads durch Time-Slicing abwechselnd ausgeführt werden, wird in dieser Thesis nicht als Parallelismus bezeichnet. Von Concurrency wird in dieser Thesis gesprochen wenn mindestens zwei Operationen auf der CPU sequenziell oder abwechselnd abgearbeitet werden.






\subsection{Performance}
(TODO: write/refactor)

Das gleichzeitige Ausführen von Operationen kann zu einer Steigerung der Performance einer Applikation führen. Die Steigerung von Performance kann in drei Kategorien unterteilt werden \cite[p. 18]{Can08}:

\emph{Reduzierte Latenzen}
	Eine Aufgabe wird in schneller ausgeführt indem sie in kleinere Aufgaben unterteilt wird, welche gleichzeitig abgearbeitet werden können. \cite[p. 18]{Can08}

\emph{Latenzen verstecken}
	Lang andauernde Aufgaben werden gebündelt und abgearbeitet. Gleichzeitig können andere Aufgaben abgearbeitet werden bis die lang andauernden Aufgaben erledigt sind. Dies kann besonders bei Netzwerk oder Festplatten Operationen sinnvoll sein da diese ansonsten den Programfluss blockeren können.

\emph{Die Menge an verarbeiteten Daten pro Zeiteinheit zu veringern}
	Wenn mehrere Tasks gleichzeitig Ausgeführt werden kann die Menge an verarbeiten Daten pro Zeiteinheit erhöht werden.	

In verteilten Systemen wie Web Applikationen ist die parallele Ausführung ein essentieller Bestandteil \cite[p. 14]{Erb2012}. 

Teile einer Applikation welche keinen gemeinsamen Status besitzen und sequentiell abgearbeitet werden können mit wenig Aufwand parallel ausgeführt werden. \cite[p. 18]{Can08}

Ein konkretes Beispiel dazu bietet ein Webserver. Mehrere Anfragen werden von unterschiedlichen Clients an einen HTTP-Webserver gesendet, welcher die Anfragen gleichzeitig verarbeitet. Der Webserver leitet die Anfragen an ein das zugehörige Program weiter welches den jeweiligem HTTP-Response sequentiell generiert. \cite[p. 18]{Can08}

Für einen modernen Webserver müssen folgende Bedingungen erfüllt sein \cite[p. 2]{Sch97}: 
\label{Webserver_Requirements}
\emph{Concurrency}
	Ein Server muss mehrere Anfragen von Clients gleichzeitig verarbeiten können. 

\emph{Efficiency}
	Der Server muss Latenzen gering halten und die CPU nicht unnötig belasten. 

\emph{Programming simplicity}
	Der Server muss einfache Schnittstellen für Concurrent Programming bieten (TODO: concurrent programming?)

\emph{Adaptability}
	Neue Protokolle wie HTTP 2.0 sollten mit minimalen Implementierungsaufwand realisierbar sein.





\subsection{Asynchrone Programmierung}
(TODO: write Section)

\subsection{Event getriebene Programmierung}
(TODO: write Section)
(TODO: write about dispatching and demultiplexing)
(TODO: write about callback functions)

\subsection{Lambdas}
Lambdas werden auch als Closures, anonyme Functions oder Blocks genannt. Lambdas sind Blöcke aus Quellcode welcher als Argument an eine Funktion übergeben werden kann. Unter anderem werden Lambdas in den folgenden Programmiersprachen unterstützt:

\begin{itemize}
  \item Lisp
  \item Ruby
  \item Javascript
  \item Java
  \item Smalltalk
\end{itemize}

Closures können auf lokale Variablen zugreifen. Das bedeutet dass eine Closure auf alle Variablen im aktuellen Kontext zugriff haben. In der Sprache Ruby werden Closures unter anderem mit geschwungenen Klammeren erstellt. \cite[]{fow04} 

\begin{lstlisting}[
	caption={},
	label=listing:closures
]
	File.open(filename) {|f| doSomethingWithFile(f)}
\end{lstlisting}
\cite[]{fow04}

In Listing \ref{listing:closures} wird eine Datei vom lokalem Filesystem geöffnet. Die Funktion open in der File Klasse akzeptiert einen Block als Argument. Die Funktion open öffnet die Datei, führt den angegebenen Block aus und schließt nach Ausführung des Blocks die Datei. Blöcke können unter anderem in Transaktionen verwendet werden. \cite[]{fow04}


\subsection{I/O Operations}
(TODO: write Section)
(TODO: add statistiks about Disk I/O, Network I/O, Memory I/O)